#+SETUPFILE: ../../configOrg/level2.org
#+OPTIONS: ':nil *:t -:t ::t <:t H:3 \n:nil ^:nil arch:headline author:t c:nil
#+OPTIONS: creator:nil d:(not "LOGBOOK") date:t e:t email:nil f:t inline:t
#+OPTIONS: num:t p:nil pri:nil prop:nil stat:t tags:t tasks:t tex:t timestamp:t
#+OPTIONS: title:t toc:t todo:t |:t
#+TITLES: python2
#+DATE: <2017-05-24 Wed>
#+AUTHORS: weiwu
#+EMAIL: victor.wuv@gmail.com
#+LANGUAGE: en
#+SELECT_TAGS: export
#+EXCLUDE_TAGS: noexport
#+CREATOR: Emacs 24.5.1 (Org mode 8.3.4)

[[http://www.pythondoc.com/pythontutorial3/][source]]
* Introduction
* Built-in Functions

** Function
- function parameter
  - pass the parameters boo(a=1,b=2) won’t change the value of the parameters themselves. the sequence of the parameters are certain, you can’t change it.

- if the input argument is un-mutable,函数中改变形参值不会改变原值。
if the input is mutable, operate on the input like append operation will change the input argument.

- a, b = b, a + b # 相当于：
#+begin_src python
t = (b, a + b) # t是一个tuple
a = t[0]
b = t[1]
#+end_src


** trouble shooting
- linux python FileNotFoundError: [Errno 2] No such file or directory:

try to use absolute path instead of relative path to read a file.

- HDF5
pip install tables

** Decorator
Decorator is way to dynamically add some new behavior to some objects. We achieve the same in Python by using closures.

In the example we will create a simple example which will print some statement before and after the execution of a function.

#+BEGIN_SRC python
>>> def my_decorator(func):
...     def wrapper(*args, **kwargs):
...         print("Before call")
...         result = func(*args, **kwargs)
...         print("After call")
...         return result
...     return wrapper
...
>>> @my_decorator
... def add(a, b):
...     "Our add function"
...     return a + b
...
>>> add(1, 3)
Before call
After call
4

#+END_SRC
Common examples for decorators are classmethod() and staticmethod().
*** classmethod(function)
Return a class method for function.

A class method receives the class as implicit first argument, just like an instance method receives the instance. To declare a class method, use this idiom:

class C(object):
    @classmethod
    def f(cls, arg1, arg2, ...):
        ...
The @classmethod form is a function decorator – see the description of function definitions in Function definitions for details.

It can be called either on the class (such as C.f()) or on an instance (such as C().f()). The instance is ignored except for its class. If a class method is called for a derived class, the derived class object is passed as the implied first argument.

Class methods are different than C++ or Java static methods. If you want those, see staticmethod() in this section.

For more information on class methods, consult the documentation on the standard type hierarchy in The standard type hierarchy.
*** staticmethod(function)
Return a static method for function.

A static method does not receive an implicit first argument. To declare a static method, use this idiom:

class C(object):
    @staticmethod
    def f(arg1, arg2, ...):
        ...
The @staticmethod form is a function decorator – see the description of function definitions in Function definitions for details.

It can be called either on the class (such as C.f()) or on an instance (such as C().f()). The instance is ignored except for its class.

Static methods in Python are similar to those found in Java or C++. Also see classmethod() for a variant that is useful for creating alternate class constructors.

For more information on static methods, consult the documentation on the standard type hierarchy in The standard type hierarchy.


** Closures
Closures are nothing but functions that are returned by another function. We use closures to remove code duplication. In the following example we create a simple closure for adding numbers.
#+BEGIN_SRC python
>>> def add_number(num):
...     def adder(number):
...         'adder is a closure'
...         return num + number
...     return adder
...
>>> a_10 = add_number(10)
>>> a_10(21)
31
>>> a_10(34)
44
>>> a_5 = add_number(5)
>>> a_5(3)
8

#+END_SRC
** iterable
An object capable of returning its members one at a time. Examples of iterables include all sequence types (such as list, str, and tuple) and some non-sequence types like dict and file and objects of any classes you define with an __iter__() or __getitem__() method. Iterables can be used in a for loop and in many other places where a sequence is needed (zip(), map(), …). When an iterable object is passed as an argument to the built-in function iter(), it returns an iterator for the object. This iterator is good for one pass over the set of values. When using iterables, it is usually not necessary to call iter() or deal with iterator objects yourself. The for statement does that automatically for you, creating a temporary unnamed variable to hold the iterator for the duration of the loop. See also iterator, sequence, and generator.
** iterator
An object representing a stream of data. Repeated calls to the iterator’s next() method return successive items in the stream. When no more data are available a StopIteration exception is raised instead. At this point, the iterator object is exhausted and any further calls to its next() method just raise StopIteration again. Iterators are required to have an __iter__() method that returns the iterator object itself so every iterator is also iterable and may be used in most places where other iterables are accepted. One notable exception is code which attempts multiple iteration passes. A container object (such as a list) produces a fresh new iterator each time you pass it to the iter() function or use it in a for loop. Attempting this with an iterator will just return the same exhausted iterator object used in the previous iteration pass, making it appear like an empty container.
** generator
A function which returns an iterator. It looks like a normal function except that it contains yield statements for producing a series of values usable in a for-loop or that can be retrieved one at a time with the next() function. Each yield temporarily suspends processing, remembering the location execution state (including local variables and pending try-statements). When the generator resumes, it picks-up where it left-off (in contrast to functions which start fresh on every invocation).
** generator expression
An expression that returns an iterator. It looks like a normal expression followed by a for expression defining a loop variable, range, and an optional if expression. The combined expression generates values for an enclosing function:
#+BEGIN_SRC python
>>> sum(i*i for i in range(10))         # sum of squares 0, 1, 4, ... 81
285

#+END_SRC



* Built-in Types
** Truth Value Testing
** Boolean Operations — and, or, not
- The ^ symbol
  - The ^ symbol is for the bitwise ‘xor’ operation, but in Python, the exponent operator symbol is **.
- the minimum value between nan and infinity is infinity.
min(np.nan, np.inf) = np.inf

- eval
eval the value of a variable name from string.
** Comparisons
** Numeric Types — int, float, complex
** Iterator Types
- xrange vs range:
there's no xrange in python 3.
- access index and value looping a list:
#+BEGIN_SRC python
for idx, val in enumerate(list):
    print(idx, val)

#+END_SRC
- iterable vs iterator vs generator:
The difference between iterables and generators: once you’ve burned through a generator once, you’re done, no more data.
#+BEGIN_SRC python
generator = (word + '!' for word in 'baby let me iterate ya'.split())
# The generator object is now created, ready to be iterated over.
# No exclamation marks added yet at this point.

for val in generator: # real processing happens here, during iteration
    print val,
baby! let! me! iterate! ya!

for val in generator:
    print val,
# Nothing printed! No more data, generator stream already exhausted above.
#+END_SRC
an iterable creates a new iterator every time it’s looped over (technically, every time iterable.__iter__() is called, such as when Python hits a “for” loop):
#+BEGIN_SRC python
class BeyonceIterable(object):
    def __iter__(self):
        """
        The iterable interface: return an iterator from __iter__().

        Every generator is an iterator implicitly (but not vice versa!),
        so implementing `__iter__` as a generator is the easiest way
        to create streamed iterables.

        """
        for word in 'baby let me iterate ya'.split():
            yield word + '!'  # uses yield => __iter__ is a generator

iterable = BeyonceIterable()

for val in iterable:  # iterator created here
    print val,
baby! let! me! iterate! ya!

for val in iterable:  # another iterator created here
    print val,
baby! let! me! iterate! ya!
#+END_SRC

- magic method __iter__:
Iterators are everywhere in Python. They are elegantly implemented within for loops, comprehensions, generators etc. but hidden in plain sight.

Iterator in Python is simply an object that can be iterated upon. An object which will return data, one element at a time.

Technically speaking, Python iterator object must implement two special methods, __iter__() and __next__(), collectively called the iterator protocol.

An object is called iterable if we can get an iterator from it. Most of built-in containers in Python like: list, tuple, string etc. are iterables.

The iter() function (which in turn calls the __iter__() method) returns an iterator from them.

- Iterating Through an Iterator in Python
use the $next()$ function to manually iterate through all the items of an iterator.
#+BEGIN_SRC python
# define a list
my_list = [4, 7, 0, 3]

# get an iterator using iter()
my_iter = iter(my_list)

## iterate through it using next()

#prints 4
print(next(my_iter))

#prints 7
print(next(my_iter))

## next(obj) is same as obj.__next__()

#prints 0
print(my_iter.__next__())

#prints 3
print(my_iter.__next__())

## This will raise error, no items left
next(my_iter)
#+END_SRC
A more elegant way of automatically iterating is by using the for loop. Using this, we can iterate over any object that can return an iterator, for example list, string, file etc.
#+BEGIN_SRC python
for element in my_list:
    print(element)
#+END_SRC
- How for loop actually works?
#+BEGIN_SRC python
for element in iterable:
    # do something with element
# Is actually implemented as.

# create an iterator object from that iterable
iter_obj = iter(iterable)

# infinite loop
while True:
    try:
        # get the next item
        element = next(iter_obj)
        # do something with element
    except StopIteration:
        # if StopIteration is raised, break from loop
        break

#+END_SRC
- example:
#+BEGIN_SRC python
class PowTwo:
    """Class to implement an iterator
    of powers of two"""

    def __init__(self, max = 0):
        self.max = max

    def __iter__(self):
        self.n = 0
        return self

    def __next__(self):
        if self.n <= self.max:
            result = 2 ** self.n
            self.n += 1
            return result
        else:
            raise StopIteration

# create an iterator and iterate through it as follows.

>>> a = PowTwo(4)
>>> i = iter(a)
>>> next(i)
1
>>> next(i)
2
>>> next(i)
4
>>> next(i)
8
>>> next(i)
16
>>> next(i)
Traceback (most recent call last):
...
StopIteration

# use a for loop to iterate over our iterator class.

>>> for i in PowTwo(5):
...     print(i)
#+END_SRC
** Sequence Types — list, tuple, range
- combine list of lists into one list, join list of lists
#+BEGIN_SRC python
import itertools
a = [["a","b"], ["c"]]
print list(itertools.chain.from_iterable(a))
# or
lambda: (lambda b: map(b.extend, big_list))([])
#+END_SRC
- find difference of two lists:
#+begin_src python
a = [1,2,3,2,1,5,6,5,5,5]
import collections
print [item for item, count in collections.Counter(a).items() if count > 1]
#+end_src

- 列表生成式
#+begin_src python
[a.lower() for a in x=['Hello', 'World', 18, 'Apple', None] if isinstance(a,str)]
#+end_src

- read file to a list:
#+begin_src python
with open(r'y:\codes\data\smart_beta_etf_list.txt', 'rb') as f:
etf_list = f.readlines()
etf_list = [x.strip() for x in etf_list]
# you may also want to remove whitespace characters like `\n` at the end of each line
#+end_src

- save a list to a file:
#+begin_src python
thefile = open('test.txt', 'w')
#+end_src

- for item in the list:
#+begin_src python
thefile.write("%s\n" % item)
#+end_src

- replace comma as next line (enter):
choose extend mode: replace ',' as \r\n

- split strings by space delimiter from reverse:
#+begin_src python
text.rsplit(' ', 1)[0]
#+end_src

- split strings by space delimiter from beginning:
#+begin_src python
text.split(' ', 1)[0]
>>>a.split('.',1)
['alvy','test.txt']
后面多了一个参数1，以第一个'.'分界，分成两个字符串，组成一个list
>>>a.rsplit('.',1)
['alvy.test','txt']
现在是rsplit函数，从右边第一个'.'分界，分成两个字符串，组成一个list
#+end_src

** 生成器generator
通过列表生成式，我们可以直接创建一个列表。但是，受到内存限制，列表容量肯定是有限的。
而且，创建一个包含100万个元素的列表，不仅占用很大的存储空间，如果我们仅仅需要访问前面几个元素，那后面绝大多数元素占用的空间都白白浪费了。
要创建一个generator，有很多种方法。第一种方法很简单，只要把一个列表生成式的[]改成()，就创建了一个generator：
如果要一个一个打印出来，可以通过next()函数获得generator的下一个返回值：
next(g)
这里，最难理解的就是generator和函数的执行流程不一样。函数是顺序执行，遇到return语句或者最后一行函数语句就返回。
而变成generator的函数，在每次调用next()的时候执行，遇到yield语句返回，再次执行时从上次返回的yield语句处继续执行。

#+begin_src python
def odd():
    print('step 1')

    yield 1
    print('step 2')
    yield(3)
    print('step 3')
    yield(5)
>>> o = odd()
>>> next(o)
step 1
1
>>> next(o)
step 2
3
>>> next(o)
step 3
5
>>> next(o)
Traceback (most recent call last):

  File "<stdin>", line 1, in <module>
StopIteration
#+end_src
A Generator is an Iterator

A function with yield in it is still a function, that, when called, returns an instance of a generator object:
#+BEGIN_SRC python
def a_function():
    "when called, returns generator object"
    yield

#+END_SRC
A generator expression also *returns a generator*:
#+BEGIN_SRC python
a_generator = (i for i in range(0))

#+END_SRC

A Generator is an Iterator

An Iterator is an Iterable

Iterators require a next or __next__ method

*** loop
- loop with batches:
#+BEGIN_SRC python
for i in tqdm(range(0, len(category), batch_size)):
    re_batch = {}
    for j in range(batch_size):
        re_batch[j] = wiki_category_re.search(category, last_span)
        if re_batch[j] is not None:
            last_span = re_batch[j].span()[1]
    upload_cat_node(re_batch)
#+END_SRC
- don't care the interator sequence:
#+BEGIN_SRC python
for _ in range(10):
    print(_)
#+END_SRC

- fetch several pairs from a dictionary:
#+BEGIN_SRC python
from itertools import islice

def take(n, iterable):
    "Return first n items of the iterable as a list"
    return list(islice(iterable, n))

n_items = take(3, dict_df_ret.items())
n_items

# or
list(islice(dictionary.items(), 3))
#+END_SRC

- iterate key and value in a dictionary:
#+begin_src python
# python 2
for index, value in dict.iteritems():
# python 3
for index, value in dict.items():
    print index, value
#+end_src
- iterate keys in a dictionary:
#+begin_src python
for k in dict:
#+end_src

- iterate a row in pandas dataframe:
#+begin_src python
DataFrame.iterrows():
return generator.
>>> df = pd.DataFrame([[1, 1.5]], columns=['int', 'float'])
>>> row = next(df.iterrows())[1]
>>> row
int      1.0
float    1.5
Name: 0, dtype: float64
>>> print(row['int'].dtype)
float64
>>> print(df['int'].dtype)
int64
#+end_src

- To preserve dtypes while iterating over the rows, it is better to use itertuples()
  - which returns tuples of the values and which is generally faster as iterrows.
** Text Sequence Type — str
** Binary Sequence Types — bytes, bytearray, memoryview
** Set Types — set, frozenset
** Mapping Types — dict
- get some keys value according to a list in a dictionary:
#+BEGIN_SRC python
value = {}
for key in finance_vocab:
    value[key] = dict_vocab.get(key)

#+END_SRC
** Context Manager Types
** Other Built-in Types
** Special Attributes -- magic method:
- getitem in a class allows its instances to use the [ ] (indexer) operators
- setitem Called to implement assignment to self[key]
- call magic method in a class causes its instances to become callables – in other words, those instances now behave like functions.
- getattr overrides Python’s default mechanism for member access.
- getattr magic method only gets invoked for attributes that are not in the dict magic attribute. Implementing getattr causes the hasattr built-in function to always return True, unless an exception is raised from within getattr.
- setattr allows you to override Python’s default mechanism for member assignment.
- The repr function also converts an object to a string. It can also be invoked using the reverse quotes (`), also called accent grave, (underneath the tilde, ~, on most keyboards). But it will convert unambitiously the object. For example, repr(datetime.datetime.now) = datetime.datetime(2018, 1, 20, 13, 32, 51, 483232).
#+begin_src python :tangle yes
print `a`
print repr(a)
#+end_src

* Built-in Exceptions
** Base classes
** Concrete exceptions
** Warnings
** Exception hierarchy
** exception
- retry:
#+BEGIN_SRC python
response = None
error = None
while response is None:
  try:
    response = doing_something()
    if response is not None:
      if 'good' in response:
        print("successfully uploaded")
      else:
        exit("reason %s"%response)
  except HttpError as e:
    if e.code in RETRIABLE_STATUS_CODES:
      error = 'A retriable HTTP error %d occurred:\n%s' % (e.resp.status,
                                                             e.content)
    else:
      raise
  except RETRIABLE_EXCEPTIONS as e:
    error = 'A retriable error occurred: %s' % e

    if error is not None:
      print error
      retry += 1
      if retry > MAX_RETRIES:
        exit('No longer attempting to retry.')

      max_sleep = 2 ** retry
      sleep_seconds = random.random() * max_sleep
      print 'Sleeping %f seconds and then retrying...' % sleep_seconds
      time.sleep(sleep_seconds)
#+END_SRC
- capture urllib error:
#+BEGIN_SRC python
import urllib2

req = urllib2.Request('http://www.python.org/fish.html')
try:
    resp = urllib2.urlopen(req)
except urllib2.HTTPError as e:
    if e.code == 404:
        # do something...
    else:
        # ...
except urllib2.URLError as e:
    # Not an HTTP-specific error (e.g. connection refused)
    # ...
else:
    # 200
    body = resp.read()

#+END_SRC
- create an exception:
#+BEGIN_SRC python
class ConstraintError(Exception):
    def __init__(self, arg):
        self.args = arg


if error:
    raise ConstraintError("error")


class Networkerror(RuntimeError):
    def __init__(self, arg):
        self.args = arg


try:
    raise Networkerror("Bad hostname")
except Networkerror,e:
    print e.args
    print e.message
#+END_SRC
* Text Processing Services
** string — Common string operations
- if the string is an English word.
#+BEGIN_SRC python
from nltk.corpus import wordnet
if not wordnet.synsets(word) and not word.isdigit()
#+END_SRC
- jieba cut, remove signs.
#+BEGIN_SRC python
punct = set(u''':!),.:;?]}¢'"、。〉》」』】〕〗〞︰︱︳﹐､﹒
﹔﹕﹖﹗﹚﹜﹞！），．：；？｜｝︴︶︸︺︼︾﹀﹂﹄﹏､～￠
々‖•·ˇˉ―--′’”([{£¥'"‵〈《「『【〔〖（［｛￡￥〝︵︷︹︻
︽︿﹁﹃﹙﹛﹝（｛“‘-—_…''')

str_in = u"小明硕士毕业于中国科学院计算所，\
后在日本京都大学深造，凭借过人天赋，旁人若在另一方面爱他，他每即躲开。"

# 对str/unicode
filterpunt = lambda s: ''.join(filter(lambda x: x not in punct, s))
# 对list
filterpuntl = lambda l: list(filter(lambda x: x not in punct, l))
seg_list = jieba.cut(str_in, cut_all=False)
sent_list = filterpuntl(seg_list)
#+END_SRC

 - create a list from jieba generator:
   sentence = [x for x in seg_list]
- tokenize unicode or string to sentence list.
#+BEGIN_SRC python
from nltk import tokenize as n_tokenize
sent= n_tokenize.sent_tokenize(page)
# or
sent_list = page.split()
#+END_SRC
- list comprehension
[x for x in t if x not in s if x.isdigit()]

- if string are digits.
#+BEGIN_SRC python
str.isdigit()
#+END_SRC
- concatenate two strings
#+BEGIN_SRC python
" ".join((str1, str2))
#+END_SRC
- 移除字符串头尾指定的字符（默认为空格）
#+BEGIN_SRC python
#!/usr/bin/python

str = "0000000this is string example....wow!!!0000000";
print(str.strip( '0' ))
#+END_SRC

- checks whether the string consists of alphabetic characters only.
#+BEGIN_SRC python 2
#!/usr/bin/python

str = "this";  # No space & digit in this string
print(str.isalpha())

str = "this is string example....wow!!!";
print(str.isalpha())
#+END_SRC

#+RESULTS:
: True
: False

** re — Regular expression operations
*** useage:
- find strings
- convert strings

*** string array
[Pp]ython: find Python or python

**** parts
re.search('[a-zA-Z0-9]', 'x')

**** not
re.search('[^0-9]', 'x')

**** shortcut

- word: \w
- number: \d
- space, tab, next line: \s
- 0 length sub string: \b
re.search('\bcorn\b', 'corner')

**** start and end with strings
#+BEGIN_SRC python
re.search('^Python', 'Python 3')
re.search('Python$', 'this is Python')
#+END_SRC

**** any character
"."

**** all lines contain a specific string
#+BEGIN_SRC python
^.*Deeplearning4j$
#+END_SRC
*** optional words
'color' vs 'colour'
re.search('colou?r', 'my favoriate color')

*** repeat
{N}

#+BEGIN_SRC python
# find a telephone number
re.search(r'[\d]{3}-[\d]{4}', '867-5309 /Jenny')

# find 32big GID
[x for x in risk_model_merge.keys() if re.match("[A-Z0-9]{32}$", x)]
#+END_SRC

**** boundary of repeated times
[\d]{3,4}

**** open selection
[\d]{3,}

**** speed selection
- +: {1,}
- *: {0,}

*** search for a pattern within a text file
- bulk read:
#+BEGIN_SRC python
import re

textfile = open(filename, 'r')
filetext = textfile.read()
textfile.close()
matches = re.findall("(<(\d{4,5})>)?", filetext)

#+END_SRC

- read line by line:
#+BEGIN_SRC python
import re

textfile = open(filename, 'r')
matches = []
reg = re.compile("(<(\d{4,5})>)?")
for line in textfile:
    matches += reg.findall(line)
textfile.close()
#+END_SRC

** difflib — Helpers for computing deltas
** textwrap — Text wrapping and filling
** unicodedata — Unicode Database
https://docs.python.org/2.7/howto/unicode.html
** stringprep — Internet String Preparation
** readline — GNU readline interface

* Data Types
** datetime — Basic date and time types
** Time
- get specific timezone datetime
#+begin_src python
tz = pytz.timezone('America/Los_Angeles')
#date = date.today()
now = datetime.now()
los_angeles_time = datetime.now(tz)
#+end_src

- use tqdm as a status bar:
#+begin_src python
from tqdm import tqdm
from time import sleep
for i in tqdm(range(10)):
    sleep(0.1)
#+end_src

- string to datetime:
#+begin_src python
time.strptime(string[, format])
#+end_src

- datetime, Timestamp, datetime64
pandas, Timestamp
np.dtype('<M8[ns]')

-- DatetimeIndex is composed by Timestamps.
#+BEGIN_SRC python
#Timestamp to string:i
str_timestamp = pd.to_datetime(Timestamp, format = '%Y%m%d')
str_timestamp = str_timestamp.strftime('%Y-%m-%d')
#+END_SRC
datetime, utc
datetime64

- datetime off set, subtract
#+BEGIN_SRC python
pd.DateOffset(years=1)
pd.Timedelta(days=365) #allowed keywords are [weeks, days, hours, minutes, seconds, milliseconds, microseconds, nanoseconds]
#+END_SRC
** calendar — General calendar-related functions
** collections — Container datatypes
** collections — High-performance container datatypes

| module      | function                                                             |
|-------------+----------------------------------------------------------------------|
| deque       | list-like container with fast appends and pops on either end         |
| Counter     | dict subclass for counting hashable objects                          |
| defaultdict | dict subclass that calls a factory function to supply missing values |

** collections.abc — Abstract Base Classes for Containers
** heapq — Heap queue algorithm
** bisect — Array bisection algorithm
** array — Efficient arrays of numeric values
** weakref — Weak references
** types — Dynamic type creation and names for built-in types
** copy — Shallow and deep copy operations
#+BEGIN_SRC python
from copy import copy
#+END_SRC
** pprint — Data pretty printer
适合打印列表。
#+BEGIN_SRC python
>>> import pprint
>>> tup = ('spam', ('eggs', ('lumberjack', ('knights', ('ni', ('dead',
... ('parrot', ('fresh fruit',))))))))
>>> stuff = ['a' * 10, tup, ['a' * 30, 'b' * 30], ['c' * 20, 'd' * 20]]
>>> pprint.pprint(stuff)
['aaaaaaaaaa',
 ('spam',
  ('eggs',
   ('lumberjack',
    ('knights', ('ni', ('dead', ('parrot', ('fresh fruit',)))))))),
 ['aaaaaaaaaaaaaaaaaaaaaaaaaaaaaa', 'bbbbbbbbbbbbbbbbbbbbbbbbbbbbbb'],
 ['cccccccccccccccccccc', 'dddddddddddddddddddd']]
#+END_SRC
** reprlib — Alternate repr() implementation
** enum — Support for enumerations
* Numeric and Mathematical Modules
** numbers — Numeric abstract base classes
** math — Mathematical functions
** cmath — Mathematical functions for complex numbers
** decimal — Decimal fixed point and floating point arithmetic
Floating-point numbers are represented in computer hardware as base 2 (binary) fractions. For example, the decimal fraction 0.001 has value 0/2 + 0/4 + 1/8.
On a typical machine running Python, there are 53 bits of precision available for a Python float, so the value stored internally when you enter the decimal number 0.1 is the binary fraction.
#+begin_src emacs-lisp :tangle yes
0.00011001100110011001100110011001100110011001100110011010
#+end_src
#+begin_src emacs-lisp :tangle yes
>>> round(2.675, 2)
2.67
#+end_src
it’s again replaced with a binary approximation, whose exact value is

2.67499999999999982236431605997495353221893310546875

** fractions — Rational numbers
** random — Generate pseudo-random numbers
** statistics — Mathematical statistics functions
* Functional Programming Modules
** itertools — Functions creating iterators for efficient looping
** functools — Higher-order functions and operations on callable objects
** operator — Standard operators as functions
* File and Directory Access
** pathlib — Object-oriented filesystem paths
** os.path — Common pathname manipulations
- temperary folder:
#+BEGIN_SRC python
import os
import tempfile
TEMP_FOLDER = tempfile.gettempdir()
print('Folder "{}" will be used to save temporary dictionary and corpus.'.format(TEMP_FOLDER))
#+END_SRC
- walk all file from a directory and its sub-directory
Directory tree generator.

For each directory in the directory tree rooted at top (including top
itself, but excluding '.' and '..'), yields a 3-tuple

    dirpath, dirnames, filenames
#+BEGIN_SRC  python
import os
from os.path import join, getsize
for root, dirs, files in os.walk('/home/weiwu/share/deep_learning/data/enwiki'):
    print(root, "consumes, ")
    print(sum([getsize(join(root, name)) for name in files]), '\s')
    print("bytes in", len(files), "non-directory files")
#+END_SRC

- check if file exist
#+BEGIN_SRC python
os.path.isfile(os.path.join(path,name))
#+END_SRC
- get current work directory
#+BEGIN_SRC python
import os
cwd = os.getcwd()
#+END_SRC
- get temporary work directory
#+BEGIN_SRC python
from tempfile import gettempdir
tmp_dir = gettempdir()
#+END_SRC
** fileinput — Iterate over lines from multiple input streams
- open
open() returns a file object, and is most commonly used with two arguments: open(filename, mode).
#+BEGIN_SRC python
>>> f = open('workfile', 'w')
>>> print f
<open file 'workfile', mode 'w' at 80a0960>
#+END_SRC
The first argument is a string containing the filename. The second argument is another string containing a few characters describing the way in which the file will be used. mode can be 'r' when the file will only be read, 'w' for only writing (an existing file with the same name will be erased), and 'a' opens the file for appending; any data written to the file is automatically added to the end. 'r+' opens the file for both reading and writing. The mode argument is optional; *r* will be assumed if it’s omitted.

On Windows, 'b' appended to the mode opens the file in binary mode, so there are also modes like 'rb', 'wb', and 'r+b'.
- write text at the end of a file without overwrite that file:
#+BEGIN_SRC python
f = open('filename.txt', 'a')
f.write("stuff")
f.close()
#+END_SRC
** stat — Interpreting stat() results
** filecmp — File and Directory Comparisons
** tempfile — Generate temporary files and directories
** glob — Unix style pathname pattern expansion
** fnmatch — Unix filename pattern matching
** linecache — Random access to text lines
** shutil — High-level file operations
** macpath — Mac OS 9 path manipulation functions
* Data Persistence
** pickle — Python object serialization
*** dump:
#+BEGIN_SRC python
import pickle

data1 = {'a': [1, 2.0, 3, 4+6j],
         'b': ('string', u'Unicode string'),
         'c': None}

selfref_list = [1, 2, 3]
selfref_list.append(selfref_list)

output = open('data.pkl', 'wb')

# Pickle dictionary using protocol 0.
pickle.dump(data1, output)

# Pickle the list using the highest protocol available.
pickle.dump(selfref_list, output, -1)

output.close()
pickle.dump( x0, open( "x0.pkl", "wb" ) )
#+END_SRC

*** load:
#+BEGIN_SRC python
import pprint, pickle

pkl_file = open('data.pkl', 'rb')

data1 = pickle.load(pkl_file)
pprint.pprint(data1)

data2 = pickle.load(pkl_file)
pprint.pprint(data2)

pkl_file.close()
#+END_SRC
** copyreg — Register pickle support functions
** shelve — Python object persistence
** marshal — Internal Python object serialization
** dbm — Interfaces to Unix “databases”
** sqlite3 — DB-API interface for SQLite databases
** protobuf
*** tutorial
- need a .proto file for the structure:
#+BEGIN_SRC proto
syntax = "proto3"; // or proto2
package tutorial;

import "google/protobuf/timestamp.proto";
// [END declaration]

// [START java_declaration]
option java_package = "com.example.tutorial";
option java_outer_classname = "AddressBookProtos";
// [END java_declaration]

// [START csharp_declaration]
option csharp_namespace = "Google.Protobuf.Examples.AddressBook";
// [END csharp_declaration]

// [START messages]
message Person {
  string name = 1;
  int32 id = 2;  // Unique ID number for this person.
  string email = 3;

  enum PhoneType {
    MOBILE = 0;
    HOME = 1;
    WORK = 2;
  }

  message PhoneNumber {
    string number = 1;
    PhoneType type = 2;
  }

  repeated PhoneNumber phones = 4;

  google.protobuf.Timestamp last_updated = 5;
}

// Our address book file is just one of these.
message AddressBook {
  repeated Person people = 1;
}

#+END_SRC
- Compiling Your Protocol Buffers in shell to generate a class:
#+BEGIN_SRC bash
protoc -I=$SRC_DIR --python_out=$DST_DIR $SRC_DIR/addressbook.proto
protoc --proto_path=src --python_out=build/gen src/foo.proto src/bar/baz.proto
# The compiler will read the files src/foo.proto and src/bar/baz.proto and produce two output files: build/gen/foo_pb2.py and build/gen/bar/baz_pb2.py. The compiler will automatically create the directory build/gen/bar if necessary, but it will not create build or build/gen; they must already exist.
#+END_SRC
- add_person.py
#+BEGIN_SRC python
#! /usr/bin/python

import addressbook_pb2
import sys

# This function fills in a Person message based on user input.
def PromptForAddress(person):
  person.id = int(raw_input("Enter person ID number: "))
  person.name = raw_input("Enter name: ")

  email = raw_input("Enter email address (blank for none): ")
  if email != "":
    person.email = email

  while True:
    number = raw_input("Enter a phone number (or leave blank to finish): ")
    if number == "":
      break

    phone_number = person.phones.add()
    phone_number.number = number

    type = raw_input("Is this a mobile, home, or work phone? ")
    if type == "mobile":
      phone_number.type = addressbook_pb2.Person.MOBILE
    elif type == "home":
      phone_number.type = addressbook_pb2.Person.HOME
    elif type == "work":
      phone_number.type = addressbook_pb2.Person.WORK
    else:
      print "Unknown phone type; leaving as default value."

# Main procedure:  Reads the entire address book from a file,
#   adds one person based on user input, then writes it back out to the same
#   file.
if len(sys.argv) != 2:
  print "Usage:", sys.argv[0], "ADDRESS_BOOK_FILE"
  sys.exit(-1)

address_book = addressbook_pb2.AddressBook()

# Read the existing address book.
try:
  f = open(sys.argv[1], "rb")
  address_book.ParseFromString(f.read())
  f.close()
except IOError:
  print sys.argv[1] + ": Could not open file.  Creating a new one."

# Add an address.
PromptForAddress(address_book.people.add())

# Write the new address book back to disk.
f = open(sys.argv[1], "wb")
f.write(address_book.SerializeToString())
f.close()
#+END_SRC
- try to run above python code in shell:
#+BEGIN_SRC bash
python add_person.py ADDRESS_BOOK_FILE
#+END_SRC
- list_person.py
#+BEGIN_SRC python
#! /usr/bin/python

import addressbook_pb2
import sys

# Iterates though all people in the AddressBook and prints info about them.
def ListPeople(address_book):
  for person in address_book.people:
    print "Person ID:", person.id
    print "  Name:", person.name
    if person.HasField('email'):
      print "  E-mail address:", person.email

    for phone_number in person.phones:
      if phone_number.type == addressbook_pb2.Person.MOBILE:
        print "  Mobile phone #: ",
      elif phone_number.type == addressbook_pb2.Person.HOME:
        print "  Home phone #: ",
      elif phone_number.type == addressbook_pb2.Person.WORK:
        print "  Work phone #: ",
      print phone_number.number

# Main procedure:  Reads the entire address book from a file and prints all
#   the information inside.
if len(sys.argv) != 2:
  print "Usage:", sys.argv[0], "ADDRESS_BOOK_FILE"
  sys.exit(-1)

address_book = addressbook_pb2.AddressBook()

# Read the existing address book.
f = open(sys.argv[1], "rb")
address_book.ParseFromString(f.read())
f.close()

ListPeople(address_book)
#+END_SRC
- read a message:
#+BEGIN_SRC bash
python list_person.py ADDRESS_BOOK_FILE
#+END_SRC
* Data Compression and Archiving
** zip
zip([iterable, ...])
This function returns a list of tuples, where the i-th tuple contains the i-th element from each of the argument sequences or iterables. The returned list is truncated in length to the length of the shortest argument sequence. When there are multiple arguments which are all of the same length, zip() is similar to map() with an initial argument of None. With a single sequence argument, it returns a list of 1-tuples. With no arguments, it returns an empty list.

The left-to-right evaluation order of the iterables is guaranteed. This makes possible an idiom for clustering a data series into n-length groups using zip(*[iter(s)]*n).

zip() in conjunction with the * operator can be used to unzip a list:
#+BEGIN_SRC shell
>>>
>>> x = [1, 2, 3]
>>> y = [4, 5, 6]
>>> zipped = zip(x, y)
>>> zipped
[(1, 4), (2, 5), (3, 6)]
>>> x2, y2 = zip(*zipped)
>>> x == list(x2) and y == list(y2)
True
#+END_SRC
- create a dictionary with two iterables
#+BEGIN_SRC python
>>> x = [1, 2, 3]
>>> y = [4, 5, 6]
>>> zipped = zip(x, y)
>>> zipped
[(1, 4), (2, 5), (3, 6)]
In [172]: dict(zipped)
Out[179]: {1: 4, 2: 5, 3: 6}

#+END_SRC
** zlib — Compression compatible with gzip
** gzip — Support for gzip files
** bz2 — Support for bzip2 compression
** lzma — Compression using the LZMA algorithm
** zipfile — Work with ZIP archives
** tarfile — Read and write tar archive files
* File Formats
** csv — CSV File Reading and Writing
** configparser — Configuration file parser
- use yaml and config file.
#+BEGIN_SRC yaml
# config.yaml
engine:
  user:
    'jack'
  password:
    'password'
#+END_SRC

#+BEGIN_SRC python
import yaml
with open(r'config.yaml', 'rb') as f:
    config = yaml.load(f)

#+END_SRC
** netrc — netrc file processing
** xdrlib — Encode and decode XDR data
** plistlib — Generate and parse Mac OS X .plist files
* Cryptographic Services
** hashlib — Secure hashes and message digests
** hmac — Keyed-Hashing for Message Authentication
** secrets — Generate secure random numbers for managing secrets
* Generic Operating System Services
** os — Miscellaneous operating system interfaces
** io — Core tools for working with streams
** time — Time access and conversions
** argparse — Parser for command-line options, arguments and sub-commands
#+BEGIN_SRC python
import argparse

logger = logging.getLogger()
handler = logging.StreamHandler()
formatter = logging.Formatter(
    '%(asctime)s %(name)-12s %(levelname)-8s %(message)s')
handler.setFormatter(formatter)
if not logger.handlers:
    logger.addHandler(handler)
    logger.setLevel(logging.DEBUG)

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "-i", "--input", required=False, help="Input word2vec model")
    parser.add_argument(
        "-o", "--output", required=False, help="Output tensor file name prefix")
    parser.add_argument(
        "-b",
        "--binary",
        required=False,
        help="If word2vec model in binary format, set True, else False")
    parser.add_argument(
        "-l",
        "--logdir",
        required=False,
        help="periodically save model variables in a checkpoint")
    parser.add_argument(
        "--host",
        required=False,
        help="host where holding the tensorboard projector service")
    parser.add_argument("-p", "--port", required=False, help="browser port")
    args = parser.parse_args()

    word2vec2tensor(args.input, args.output, args.binary)

#+END_SRC
** getopt — C-style parser for command line options
** logging — Logging facility for Python
#+BEGIN_SRC python
import logging
logger = logging.getLogger()
handler = logging.StreamHandler()
formatter = logging.Formatter('%(asctime)s %(name)-12s %(levelname)-8s %(message)s')
handler.setFormatter(formatter)
if not logger.handler:
    logger.addHandler(handler)
logger.setLevel(logging.DEBUG)
logger

# at the end of the program
handler.close()
logger.removeHandler(handler)
#+END_SRC

** logging.config — Logging configuration
** logging.handlers — Logging handlers
** getpass — Portable password input
** curses — Terminal handling for character-cell displays
** curses.textpad — Text input widget for curses programs
** curses.ascii — Utilities for ASCII characters
** curses.panel — A panel stack extension for curses
** platform — Access to underlying platform’s identifying data
** errno — Standard errno system symbols
** ctypes — A foreign function library for Python
* Concurrent Execution
** threading — Thread-based parallelism
** threading & queue
*** install
#+BEGIN_SRC shell
pip install queuelib
#+END_SRC
*** example
#+BEGIN_SRC python
from Queue import Queue
import threading

#+END_SRC
** multiprocessing — Process-based parallelism
** The concurrent package
** concurrent.futures — Launching parallel tasks
** subprocess — Subprocess management
** sched — Event scheduler
** queue — A synchronized queue class
** dummy_threading — Drop-in replacement for the threading module
** _thread — Low-level threading API
** _dummy_thread — Drop-in replacement for the _thread module

* Internet Data Handling
** Jupyter notebook
*** Using a virtualenv in an IPython notebook
1. Install the ipython kernel module into your virtualenv
#+BEGIN_SRC python
workon my-virtualenv-name  # activate your virtualenv, if you haven't already
pip install ipykernel
#+END_SRC

2. Now run the kernel "self-install" script:
#+BEGIN_SRC python
python -m ipykernel install --user --name=my-virtualenv-name
#+END_SRC

** fetch data from yahoo
install pandas-datareader first.
#+BEGIN_SRC shell
conda install pandas-datareader
#+END_SRC

#+begin_src python
import pandas as pd
import datetime as dt
import numpy as np
from pandas_datareader import data as web

data = pd.DataFrame()
symbols = ['GLD', 'GDX']
for sym in symbols:
    data[sym] = web.DataReader(sym, data_source='yahoo', start='20100510')['Adj Close']
data = data.dropna()
#+end_src

** email — An email and MIME handling package
** json — JSON encoder and decoder

* Internet Protocols and Support
** webbrowser — Convenient Web-browser controller
** cgi — Common Gateway Interface support
** cgitb — Traceback manager for CGI scripts
** wsgiref — WSGI Utilities and Reference Implementation
** urllib — URL handling modules
** urllib.request — Extensible library for opening URLs
** urllib.response — Response classes used by urllib
** urllib.parse — Parse URLs into components
** urllib.error — Exception classes raised by urllib.request
** urllib.robotparser — Parser for robots.txt
** http — HTTP modules
** http.client — HTTP protocol client
** ftplib — FTP protocol client
** poplib — POP3 protocol client
** imaplib — IMAP4 protocol client
** nntplib — NNTP protocol client
** smtplib — SMTP protocol client
** smtpd — SMTP Server
** telnetlib — Telnet client
** uuid — UUID objects according to RFC 4122
** socketserver — A framework for network servers
** http.server — HTTP servers
** http.cookies — HTTP state management
** http.cookiejar — Cookie handling for HTTP clients
** xmlrpc — XMLRPC server and client modules
** xmlrpc.client — XML-RPC client access
** xmlrpc.server — Basic XML-RPC servers
** ipaddress — IPv4/IPv6 manipulation library

* Development Tools
** typing — Support for type hints
** pydoc — Documentation generator and online help system
** doctest — Test interactive Python examples
** unittest — Unit testing framework
- check data operation:
  - create, select, update, delete.

- purpose of unit test
  - checking parameter types, classes, or values.
  - checking data structure invariants.
  - checking “can’t happen” situations (duplicates in a list, contradictory state variables.)
  - after calling a function, to make sure that its return is reasonable.

** unittest.mock — mock object library
** unittest.mock — getting started

** test — Regression tests package for Python
** test.support — Utilities for the Python test suite
* Debugging and Profiling
** bdb — Debugger framework
** faulthandler — Dump the Python traceback
** pdb — The Python Debugger
** The Python Profilers
STEPS:
1). install snakeviz using pip from cmd.
#+BEGIN_SRC shell
pip install snakeviz
#+END_SRC

2). profile the test python file using below command.
#+BEGIN_SRC shell
$ python -m cProfile -o profile.stats test.py
#+END_SRC
#+BEGIN_SRC python
# test.py
from random import randint
max_size = 10**4
data = [randint(0, max_size) for _ in range(max_size)]
test = lambda: insertion_sort(data)

#+END_SRC

3). check the efficiency result from profile.stats file.
#+BEGIN_SRC shell
$ snakeviz profile.stats
#+END_SRC

** timeit — Measure execution time of small code snippets
** trace — Trace or track Python statement execution
** tracemalloc — Trace memory allocations
* Software Packaging and Distribution
** pip
- install with a wheel .whl file:
#+BEGIN_SRC bash
pip install *.whl
#+END_SRC
- Upgrading pip
#+BEGIN_SRC bash
pip install -U pip
#+END_SRC
- add below setup to ~/.pip/pip.conf
#+begin_src txt
[global]
#index-url=https://pypi.mirrors.ustc.edu.cn/simple/
#index-url=https://pypi.python.org/simple/
index-url=http://mirrors.aliyun.com/pypi/simple/
#index-url=https://pypi.gocept.com/pypi/simple/
#index-url=https://mirror.picosecond.org/pypi/simple/
[install]
trusted-host=mirrors.aliyun.com
#trusted-host=mirrors.ustc.edu.cn
#+end_src
- generate a requirements file:
#+BEGIN_SRC bash
pip freeze > requirements.txt
#+END_SRC
- pip install directly:
requirements.txt
#+begin_src txt
--index-url http://mirrors.aliyun.com/pypi/simple/
pandas
pylint
pep8
sphinx
ipython
numpy
ipdb
mock
nose
#+end_src
** distutils — Building and installing Python modules
** ensurepip — Bootstrapping the pip installer
** venv — Creation of virtual environments
** zipapp — Manage executable python zip archives
** pyenv — Simple Python version management
- check installed versions
#+BEGIN_SRC shell
pyenv versions
#+END_SRC

#+RESULT:
:  system
:  2.7.13
:  3.6.0
:  3.6.0/envs/general
:  3.6.0/envs/simulate
:  3.6.0/envs/venv3.6.0
:  3.6.0/envs/venv3.6.0.1
: * anaconda3-4.4.0 (set by /home/weiwu/projects/simulate/.python-version)
:  general
:  simulate
:  venv3.6.0
:  venv3.6.0.1

* Python Runtime Services
** sysconfig — Provide access to Python’s configuration information
** os, sys — System-specific parameters and functions
- check if file or directory exists, if not then make directory:
#+BEGIN_SRC python
import os
os.path.exists(test_file.txt)
os.path.isfile("test-data")
export_dir = "export/"
if not os.path.exists(export_dir):
    os.mkdir(export_dir)
#+END_SRC

 - read a file:
import os
folder = '/file/path'
file = os.path.join(folder, 'file_name')

- list all the files under a directory:
#+BEGIN_SRC python
# os.listdir() 方法用于返回指定的文件夹包含的文件或文件夹的名字的列表。这个列表以字母顺序。 它不包括 '.' 和'..' 即使它在文件夹中.
path = os.getcwd()
dirs = os.listdir(path)
#+END_SRC

- check if the file readable:
#+BEGIN_SRC python
import os
if os.access("/file/path/foo.txt", os.F_OK):
    print "Given file path is exist."

if os.access("/file/path/foo.txt", os.R_OK):
    print "File is accessible to read"

if os.access("/file/path/foo.txt", os.W_OK):
    print "File is accessible to write"

if os.access("/file/path/foo.txt", os.X_OK):
    print "File is accessible to execute"

#+END_SRC
- use sys to get command arguments:
#+BEGIN_SRC python
#!/usr/bin/python3

import sys

print ('参数个数为:', len(sys.argv), '个参数。')
print ('参数列表:', str(sys.argv))

#+END_SRC
#+BEGIN_SRC shell
$ python3 test.py arg1 arg2 arg3
参数个数为: 4 个参数。
参数列表: ['test.py', 'arg1', 'arg2', 'arg3']
#+END_SRC

** builtins — Built-in objects
** __main__ — Top-level script environment
** warnings — Warning control
** contextlib — Utilities for with-statement contexts
** abc — Abstract Base Classes
** atexit — Exit handlers
** traceback — Print or retrieve a stack traceback
** __future__ — Future statement definitions
从Python 2.7到Python 3.x就有不兼容的一些改动，比如2.x里的字符串用'xxx'表示str，Unicode字符串用u'xxx'表示unicode，而在3.x中，所有字符串都被视为unicode，因此，写u'xxx'和'xxx'是完全一致的，而在2.x中以'xxx'表示的str就必须写成b'xxx'，以此表示“二进制字符串”。

要直接把代码升级到3.x是比较冒进的，因为有大量的改动需要测试。相反，可以在2.7版本中先在一部分代码中测试一些3.x的特性，如果没有问题，再移植到3.x不迟。

Python提供了__future__模块，把下一个新版本的特性导入到当前版本，于是我们就可以在当前版本中测试一些新版本的特性。
#+BEGIN_SRC python
from __future__ import print_function
from __future__ import division
from __future__ import unicode_literals
from __future__ import absolute_import
#+END_SRC
- unicode vs utf-8 vs binary strings vs strings
unicode 是编码unique code,例如把一个汉字编成了一个码(计算机不可读).

A chinese character:      汉

it's unicode value:       U+6C49

convert 6C49 to binary:   01101100 01001001

UTF-8是把character转为binary code的规范, and vice versa. 方便存储。
|   binary |          |          |          |                     |                                   |
| 1st Byte | 2nd Byte | 3rd Byte | 4th Byte | Number of Free Bits | Maximum Expressible Unicode Value |
| 0xxxxxxx |          |          |          | 7                   | 007F hex (127)                    |
| 110xxxxx | 10xxxxxx |          |          | (5+6)=11            | 07FF hex (2047)                   |
| 1110xxxx | 10xxxxxx | 10xxxxxx |          | (4+6+6)=16          | FFFF hex (65535)                  |
| 11110xxx | 10xxxxxx | 10xxxxxx | 10xxxxxx | (3+6+6+6)=21        | 10FFFF hex (1,114,111)            |

- division
新的除法特性，本来的除号`/`对于分子分母是整数的情况会取整，但新特性中在此情况下的除法不会取整，取整的使用`//`。如下可见，只有分子分母都是整数时结果不同。
- print_function
新的print是一个函数，如果导入此特性，之前的print语句就不能用了。
- unicode_literals
这个是对字符串使用unicode字符

** gc — Garbage Collector interface
** inspect — Inspect live objects
** site — Site-specific configuration hook
** fpectl — Floating point exception control
* Custom Python Interpreters
** code — Interpreter base classes
** codeop — Compile Python code
* Importing Modules
** Module
- 当你运行一个Python模块 python fibo.py <arguments>
  Remember, everything in python is an object.

- python解释器CPython.

- 如果字符串里面有’\’,而实际上要把斜杠加到字符串里面，要在前面加r，代表raw. 例如r’Y:\codes’.

- 如果主目录下有子目录packages，记得要在子目录下加init.py，最好在主目录下建main.py函数。

- 解释器如果执行哪个一个文件为主程序，如 python program1.py，it will set the special variable name to program1.py equals to ‘main’
- One of the reasons for doing this is that sometimes you write a module (a .py file) where it can be executed directly. Alternatively, it can also be imported and used in another module. By doing the main check, you can have that code only execute when you want to run the module as a program and not have it execute when someone just wants to import your module and call your functions themselves.

- 模块中的代码将会被执行，就像导入它一样，不过此时name 被设置为 “main“。这意味着，通过在你的模块末尾添加此代码.

- can’t import module from upper directory.

    - need to add the working directory to .bashrc PYTHONPATH
    - using ipython.
- Add custom folder path to the Windows environment.
  add PYTHONEXE%; to System Variable PATH;
  add System variable name: PYTHONEXE , value: C:\Users\Wei Wu\Anaconda2;C:\Users\Wei Wu\Python\ylib\src\py\;
  add PYTHONPATH:  C:\Users\Wei Wu\Anaconda2;C:\Users\Wei Wu\Python\ylib\src\py\;
  or add module path in Spyder directly;
- import module temperarily from parental directory without add path to the system.
#+begin_src python :tangle yes
# folder1
#    \__init__.py
#    \State.py
#    \StateMachine.py
#    \mouse_folder
#        \MouseAction.py
import os,sys,inspect
currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))
parentdir = os.path.dirname(currentdir)
sys.path.insert(0,parentdir+'\\mouse')
sys.path.insert(0,parentdir)

from State import State
from StateMachine import StateMachine
from MouseAction import MouseAction
#+end_src

- check module path:
#+begin_src python
import os
print os.path.abspath(ylib.__file__)
#+end_src

- make a python 3 virtual environment:
#+begin_src sh
mkvirtual -p python3 ENVNAME
#+end_src

- install setup.py:
python setup.py install
to virtual environment:
/home/weiwu/.virtualenvs/data_analysis/bin/python2 setup.py install

- install from github:
pip install git+https://github.com/quantopian/zipline.git

- change conda source:
#+BEGIN_SRC shell
conda config --add channels 'https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/'
conda config --set show_channel_urls yes
#+END_SRC

- create conda virtualenv:
#+BEGIN_SRC shell
# 创建 conda 虚拟环境（ :code:`env_name` 是您希望创建的虚拟环境名）
$ conda create --name env_name python=3.5

# 如您想创建一个名为rqalpha的虚拟环境
$ conda create --name rqalpha python=3.5

# 使用 conda 虚拟环境
$ source activate env_name
# 如果是 Windows 环境下 直接执行 activcate
$ activate env_name

# 退出 conda 虚拟环境
$ source deactivate env_name
# 如果是 Windows 环境下 直接执行 deactivate
$ deactivate env_name

# 删除 conda 虚拟环境
$ conda-env remove --name env_name

#+END_SRC

- percentage output format:
#+begin_src python
from future import division
print “%s %.4f%%” % (sid, (len(not_close)/len(ctp)))
#+end_src
** zipimport — Import modules from Zip archives
** pkgutil — Package extension utility
** modulefinder — Find modules used by a script
** runpy — Locating and executing Python modules
** importlib — The implementation of import
* Python Language Services
** parser — Access Python parse trees
** ast — Abstract Syntax Trees
** symtable — Access to the compiler’s symbol tables
** symbol — Constants used with Python parse trees
** token — Constants used with Python parse trees
** keyword — Testing for Python keywords
** tokenize — Tokenizer for Python source
** tabnanny — Detection of ambiguous indentation
** pyclbr — Python class browser support
** py_compile — Compile Python source files
** compileall — Byte-compile Python libraries
** dis — Disassembler for Python bytecode
** pickletools — Tools for pickle developers
* Miscellaneous Services
** formatter — Generic output formatting
* MS Windows Specific Services
** msilib — Read and write Microsoft Installer files
** msvcrt — Useful routines from the MS VC++ runtime
** winreg — Windows registry access
** winsound — Sound-playing interface for Windows
* Unix Specific Services
** posix — The most common POSIX system calls
** pwd — The password database
** spwd — The shadow password database
** grp — The group database
** crypt — Function to check Unix passwords
** termios — POSIX style tty control
** tty — Terminal control functions
** pty — Pseudo-terminal utilities
** fcntl — The fcntl and ioctl system calls
** pipes — Interface to shell pipelines
** resource — Resource usage information
** nis — Interface to Sun’s NIS (Yellow Pages)
** syslog — Unix syslog library routines
* Superseded Modules
** optparse — Parser for command line options
** imp — Access the import internals
* Undocumented Modules
** Platform specific modules
* Data Analysis:
** pandas:
[[file:./pandas.org][advanced pandas]]
- read csv without header, delimiter is space:
#+BEGIN_SRC python
vocab = pd.read_csv("/home/weiwu/share/deep_learning/data/model/phrase/zhwiki/categories/三板.vocab",delim_whitespace=True,header=None)
#+END_SRC
- parse text in csv
#+BEGIN_SRC python
reddit_news = pd.read_csv('/home/weiwu/share/deep_learning/data/RedditNews.csv')
DJA_news = pd.read_csv(
    '/home/weiwu/share/deep_learning/data/Combined_News_DJIA.csv')
na_str_DJA_news = DJA_news.iloc[:, 2:].values
na_str_DJA_news = na_str_DJA_news.flatten()
na_str_reddit_news = reddit_news.News.values
sentences_reddit = [s.encode('utf-8').split() for s in na_str_reddit_news]
sentences_DJA = [s.encode('utf-8').split() for s in na_str_DJA_news]
#+END_SRC
- rank
DataFrame.rank(axis=0, method='average', numeric_only=None, na_option='keep', ascending=True, pct=False)[source]
Compute numerical data ranks (1 through n) along axis. Equal values are assigned a rank that is the average of the ranks of those values

- n largest value
DataFrame.nlargest(n, columns, keep='first')
Get the rows of a DataFrame sorted by the n largest values of columns.

#+BEGIN_SRC python
>>> df = DataFrame({'a': [1, 10, 8, 11, -1],
...                 'b': list('abdce'),
...                 'c': [1.0, 2.0, np.nan, 3.0, 4.0]})
>>> df.nlargest(3, 'a')
    a  b   c
3  11  c   3
1  10  b   2
2   8  d NaN

#+END_SRC
- quantile
DataFrame.quantile(q=0.5, axis=0, numeric_only=True, interpolation='linear')[source]
Return values at the given quantile over requested axis, a la numpy.percentile.
#+BEGIN_SRC python
>>> df = DataFrame(np.array([[1, 1], [2, 10], [3, 100], [4, 100]]),
                   columns=['a', 'b'])
>>> df.quantile(.1)
a    1.3
b    3.7
dtype: float64
>>> df.quantile([.1, .5])
       a     b
0.1  1.3   3.7
0.5  2.5  55.0
#+END_SRC

- generate a dataframe:
#+begin_src python
dates = pd.date_range('1/1/2000', periods=8)
df = pd.DataFrame(np.random.randn(8, 4), index=dates, columns=['A', 'B', 'C', 'D'])
#+end_src

- create diagonal matrix/dataframe using a series:
#+BEGIN_SRC python
df = pd.DataFrame(np.diag(s), columns=Q.index)
#+END_SRC

- connection with mysql:
#+begin_src python
pandas.read_sql_query(sql, con=engine):
pandas.read_sql_table(table_name, con=engine):
pandas.read_sql(sql, con=engine)
sql = 'DROP TABLE IF EXISTS etf_daily_price;'
result = engine.execute(sql)
#+end_src
- dropna:
#+BEGIN_SRC python
DataFrame.dropna(axis=0, how='any', thresh=None, subset=None, inplace=False)

#+END_SRC
- melt.
pandas.melt(frame, id_vars=None, value_vars=None, var_name=None, value_name='value', col_level=None)[source]

This function is useful to massage a DataFrame into a format where one or more columns are identifier variables (id_vars), while all other columns, considered measured variables (value_vars), are “unpivoted” to the row axis, leaving just two non-identifier columns, ‘variable’ and ‘value’.
#+BEGIN_SRC python
"""
Parameters:
frame : DataFrame
id_vars : tuple, list, or ndarray, optional
Column(s) to use as identifier variables.
value_vars : tuple, list, or ndarray, optional
Column(s) to unpivot. If not specified, uses all columns that are not set as id_vars.
var_name : scalar
Name to use for the ‘variable’ column. If None it uses frame.columns.name or ‘variable’.
value_name : scalar, default ‘value’
Name to use for the ‘value’ column.
col_level : int or string, optional
If columns are a MultiIndex then use this level to melt.
"""
DataFrame['idname'] = DataFrame.index
pd.melt(DataFrame, id_vars=['idname'])
#+END_SRC
#+RESULT:
: >>> import pandas as pd
: >>> df = pd.DataFrame({'A': {0: 'a', 1: 'b', 2: 'c'},
: ...                    'B': {0: 1, 1: 3, 2: 5},
: ...                    'C': {0: 2, 1: 4, 2: 6}})
: >>> df
:    A  B  C
: 0  a  1  2
: 1  b  3  4
: 2  c  5  6
: >>> pd.melt(df, id_vars=['A'], value_vars=['B'])
:    A variable  value
: 0  a        B      1
: 1  b        B      3
: 2  c        B      5

- fill nan:
#+BEGIN_SRC python
DataFrame.fillna(value=None, method=None, axis=None, inplace=False, limit=None, downcast=None, **kwargs)
# method : {‘backfill’, ‘bfill’, ‘pad’, ‘ffill’, None}, default None
#+END_SRC

- select non zero rows from series:
#+BEGIN_SRC python
s[s.nonzero()]
#+END_SRC

- create value by cretics
#+BEGIN_SRC python
df[df.col1.map(lambda x: x != 0)] = 1
#+END_SRC

- dataframe to series:
#+BEGIN_SRC python
s = df[df.columns[0]]
#+END_SRC

- replace value:
#+BEGIN_SRC python
DataFrame.replace(to_replace=None, value=None, inplace=False, limit=None, regex=False, method='pad', axis=None)
#+END_SRC
- pandas has value:
#+BEGIN_SRC python
value in df['column_name']
set(a).issubset(df['a'])
#+END_SRC

- calculate percentage of sum on a row:
#+BEGIN_SRC python
df.apply(lambda x: x / x.sum() * 100, axis=0)
#+END_SRC

- pandas has null value:
#+BEGIN_SRC python
df.isnull().values.any()

#+END_SRC
- find all the values of TRUE in a dataframe:
#+begin_src python
z=(a!=b)
pd.concat([a.ix[z[reduce(lambda x, y: x | z[y], z, False)].index],b.ix[z[reduce(lambda x, y: x | z[y], z, False)].index]],axis=1)
#+end_src

- if array a is a subset of another array b:
#+BEGIN_SRC python
set(B).issubset(set(A))
#+END_SRC
- remove negative value from a column:
#+begin_src python
filtered_1=b[‘TRADE_size’].apply(lambda x: 0 if x < 0 else x)
b[‘TRADE_size’].loc[ b[‘TRADE_size’]<0, ‘TRADE_size’] = 0
#+end_src

- drop a lable:
#+BEGIN_SRC python
DataFrame.drop(labels, axis=0, level=None, inplace=False, errors='raise')
#+END_SRC

- check if any value is NaN in DataFrame
#+BEGIN_SRC python
df.isnull().values.any()
df.isnull().any().any()
#+END_SRC

- maximum & minimum value of a dataframe:
#+BEGIN_SRC python
df.values.max()
df.values.min()
#+END_SRC

- select value by creteria:
#+BEGIN_SRC python
logger.debug("all weight are bigger than 0? %s", (df_opts_weight>0).all().all())
logger.debug("all weight are smaller than 1? %s", (df_opts_weight<=1).all().all())
logger.debug("weight sum smaller than 0: %s", df_opts_weight[df_opts_weight<0].sum(1))
#+END_SRC

- count all duplicates:
#+BEGIN_SRC python
import pandas as pd
In [15]: a=pd.DataFrame({'a':['KBE.US','KBE.US','KBE.US','KBE.US','KBE.US','KBE.US','O.US','O.US','O.US','O.US','O.US'],'b':['KBE','KBE','KBE','KBE','KBE','KBE','O','O','O','O','O']})

In [16]: count = a.groupby('a').count()

In [20]: (count>5).all().all()
Out[20]: False

In [21]: (count>4).all().all()
Out[21]: True

- datetime64[ns] missing data, null:
For datetime64[ns] types, NaT represents missing values. This is a pseudo-native sentinel value that can be represented by numpy in a singular dtype (datetime64[ns]). pandas objects provide intercompatibility between NaT and NaN.

#+BEGIN_SRC python
In [16]: df2
Out[16]:
        one       two     three four   five  timestamp
a -0.166778  0.501113 -0.355322  bar  False 2012-01-01
c -0.337890  0.580967  0.983801  bar  False 2012-01-01
e  0.057802  0.761948 -0.712964  bar   True 2012-01-01
f -0.443160 -0.974602  1.047704  bar  False 2012-01-01
h -0.717852 -1.053898 -0.019369  bar  False 2012-01-01

In [17]: df2.loc[['a','c','h'],['one','timestamp']] = np.nan

In [18]: df2
Out[18]:
        one       two     three four   five  timestamp
a       NaN  0.501113 -0.355322  bar  False        NaT
c       NaN  0.580967  0.983801  bar  False        NaT
e  0.057802  0.761948 -0.712964  bar   True 2012-01-01
f -0.443160 -0.974602  1.047704  bar  False 2012-01-01
h       NaN -1.053898 -0.019369  bar  False        NaT
#+END_SRC
- rename column names:
#+begin_src python
df_bbg = df_bbg.rename(columns = lambda x: x[:4].replace(' ',''))
#+end_src
  - rename according to column value type:
    #+BEGIN_SRC python
    name = {2:'idname', 23:'value', 4:'variable'}
    df.rename(columns=lambda x: name[(gftIO.get_column_type(df,x))], inplace=True)
    #+END_SRC
  - rename column according to value:
  #+BEGIN_SRC python
name = {'INNERCODE': 'contract_code', 'OPTIONCODE': 'contract_name',
        'SETTLEMENTDATE': 'settlement_date', 'ENDDATE': 'date',
        'CLOSEPRICE': 'close_price'}
data.rename(columns=lambda x: name[x], inplace=True)

  #+END_SRC
- remove characters after space:
#+begin_src python
df_bbg = df_bbg.rename(columns = lambda x: x.)
#+end_src

- pandas long format to pivot:
#+begin_src python
pivoted = df.pivot('name1','name2','name3')
specific_risk = self.risk_model['specificRisk'].pivot(
    index='date', columns='symbol', values='specificrisk')
df_pivot_industries_asset_weights = pd.pivot_table(
        df_industries_asset_weight, values='value', index=['date'],
        columns=['industry', 'symbol'])
#+end_src

- change the time or date or a datetime:
#+begin_src python
end = end.replace(hour=23, minute=59, second=59)
#+end_src

- 万德 wind python pandas
#+begin_src python
df = pd.Dataframe(data = w.wsd().Data[0], index=w.wsd().Times)
#+end_src

- check DatetimeIndex difference:
#+BEGIN_SRC python
# to check the frequency of the strategy, DAILY or MONTHLY
dt_diff = df_single_period_return.index.to_series().diff().mean()
if dt_diff < pd.Timedelta('3 days'):
#+END_SRC
- time delta
#+BEGIN_SRC python
import datetime
s + datetime.timedelta(minutes=5)
#+END_SRC
- resample by month and keep the last valid row
#+BEGIN_SRC python
benchmark_weight.index.name = 'Date'
m = benchmark_weight.index.to_period('m')
benchmark_weight = benchmark_weight.reset_index().groupby(m).last().set_index('Date')
benchmark_weight.index.name = ''
#+END_SRC

*** multiplying
- the multiplying calculation is not about the sequence of the index or column.

pandas will calculate on a sorted index and column value.
#+BEGIN_SRC python
In [87]: a=pd.DataFrame({'dog':[1,2],'fox':[3,4]},index=['a','b'])

In [88]: a
Out[88]:
   dog  fox
a    1    3
b    2    4

In [89]: b=pd.DataFrame({'fox':[1,2],'dog':[3,4]},index=['b','a'])

In [94]: b
Out[94]:
   dog  fox
b    3    1
a    4    2

In [95]: a*b
Out[95]:
   dog  fox
a    4    6
b    6    4
#+END_SRC

- dot multiplying
dot multiplying will sort the value.
#+BEGIN_SRC python
In [99]: a.dot(b.T)
Out[99]:
    b   a
a   6  10
b  10  16

In [100]: b.T
Out[104]:
     b  a
dog  3  4
fox  1  2

In [105]: a
Out[105]:
   dog  fox
a    1    3
b    2    4
#+END_SRC
*** Index
**** Index manuplication
- set column as datetime index
#+begin_src python
df = df.set_index(pd.DatetimeIndex(df['Date']))
#+end_src

- concaterate:
#+begin_src python
pd.concat([df1, df2], axis=0).sort_index()
pd.concat([df1, df2], axis=1)
result = df1.join(df2, how='outer’)
#+end_src

- check if the index is datetimeindex:
#+BEGIN_SRC python
if isinstance(df_otv.index, pd.DatetimeIndex):
    df_otv.reset_index(inplace=True)

#+END_SRC
- pandas are two dataframe identical
#+BEGIN_SRC python
pandas.DataFrame.equals()

#+END_SRC
- change index name:
#+begin_src python
df.index.names = ['Date']
#+end_src

- for loop in pandas dataframe:
#+begin_src python
for index, value in DataFrame:
#+end_src

- compare two time series:
#+begin_src python
s1[s1.isin(s2)]
ax = df1.plot()
df2.plot(ax=ax)
#+end_src

- datetime to string:
#+begin_src python
df.index.strftime("%Y-%m-%d %H:%M:%S")
#+end_src

- concaterate index
#+begin_src python
pd.concat([df1, df2], axis=1)
#+end_src
concate will take two dataframe to a new dataframe by index, preserving the columns.
A:
index variable value
B:
index variable value

pd.concat([A, B])
index variable value variable value
**** merge
merge will take two dataframe to a new dataframe by index, on the columns.
A:
index variable value
B:
index variable value

pd.merge(A, B, how='left', on=['index', 'variable'])
index variable value value
**** update
update dataframe1 with dataframe2

**** access hierarchical index.
  - A MultiIndex can be created from a list of arrays (using MultiIndex.from_arrays), an array of tuples (using MultiIndex.from_tuples), or a crossed set of iterables (using MultiIndex.from_product).
#+begin_src python
df.loc[‘date’,’col’], df[‘date’], df.ix[[‘date1’, ‘date2’]]
#+end_src

- slicing:
#+begin_src python
df.loc['start':'end',], df['start': 'end']
#+end_src

- slice with a ‘range’ of values, by providing a slice of tuples:
#+begin_src python
df.loc[('2006-11-02','USO.US'):('2006-11-06','USO.US')]
df.loc(axis=0)[:,['SPY.US']]
#+end_src

- select certain columns:
#+begin_src python
df.loc(axis=0)[:,['SPY.US']]['updatedTime']
#+end_src

- select rows with certain column value:
#+BEGIN_SRC python
df.loc[df['column_name'].isin(some_values)]
#+END_SRC

- select date range using pd series.
#+begin_src python
date_not_inserted = whole_index[~whole_index.isin(date_in_database['date'])]
df_need_to_be_updated = whole_df_stack.ix[days_not_in_db]
#+end_src

**** remove pandas duplicated index
***** #1
#+begin_src python
grouped = sym.groupby(level=0)
sym = grouped.last()
#+end_src

***** #2
#+begin_src python
df2[~df2.index.duplicated()]
#+end_SRC

***** remove duplicated rows
#+BEGIN_SRC python
pandas.DataFrame.drop_duplicates(subset=None, keep='first', inplace=False)
# subset : column label or sequence of labels, optional
#+END_SRC
**** convert a dataframe to an array:
#+begin_src emacs-lisp :tangle yes
pd.dataframe.to_matrix()
#+end_src

**** panel:
- create from dictionary:
#+BEGIN_SRC python
datetime_index = pd.DatetimeIndex(assets_group['date'].unique())
panel_model = pd.Panel({date: pd.DataFrame(0, index=assets.loc[date,'variable'],
                                           columns=assets.loc[date,'variable']) for date in datetime_index})
#+END_SRC
pandas panel item axis should be datetime64, this should not be an array.
** numpy
- maximum value in each row
#+BEGIN_SRC python
np.amax(ar, axis=1)
#+END_SRC
- from 2-D array to 1-D array with one column
#+BEGIN_SRC python
import numpy as np
a = np.array([[1],[2],[3]]))
a.flattern()
#+END_SRC
- Take a sequence of 1-D arrays and stack them as columns to make a single 2-D:
#+BEGIN_SRC python
numpy.column_stack(tup)
Parameters:
tup : sequence of 1-D or 2-D arrays.
Arrays to stack. All of them must have the same first dimension.
>>> a = np.array((1,2,3))
>>> b = np.array((2,3,4))
>>> np.column_stack((a,b))

- expand 1-D numpy array to 2-D:

#+END_SRC

- expand the shape of an array:
#+BEGIN_SRC python
numpy.expand_dims(a, axis)
# Expand the shape of an array.
# Insert a new axis that will appear at the axis position in the expanded array shape.
>>> x = np.array([1,2])
>>> x.shape
(2,)
>>> y = np.expand_dims(x, axis=0)
>>> y
array([[1, 2]])
>>> y.shape
(1, 2)
#+END_SRC

- count nan:
#+begin_src python
np.count_nonzero(~np.isnan(df['series']))
#+end_src

- count number of negative value:
#+begin_src python
np.sum((df < 0).values.ravel())
#+end_src

- check the difference of two arrays:
numpy.setdiff1d:
Return the sorted, unique values in ar1 that are not in ar2
#+BEGIN_SRC python
np.setdiff1d(ar1, ar2)
#+END_SRC

- reshape:
np.reshape((1, -1)), -1 means automatic number of columns.

- select random symbols from a listdir:
#+BEGIN_SRC python
# get random symbols at the target position limit
position_limit = 8
arr = list(range(len(target_symbols)))
np.random.shuffle(arr)
target_symbols = target_symbols[arr[:position_limit]]
#+END_SRC
** plot:
*** subplot with the same axis:
pandas plot.
using matplotlib:
- plot different series on the same chart.
#+BEGIN_SRC python
cl_active_contract_pricing.plot()
cl_pricing.plot(style='k--')
#+END_SRC
- plot in ipython or jupyter notebook:
#+BEGIN_SRC python
ax = contract_data.plot(legend=True)
continuous_price.plot(legend=True, style='k--', ax=ax)
plt.show()
#+END_SRC
- multiple subplots
#+begin_src python
import matplotlib.pyplot as plt
fig = plt.figure()
ax1 = fig.add_subplot(2, 2, 1)
ax2 = fig.add_subplot(2, 2, 2)
ax3 = fig.add_subplot(2, 2, 3)
fig, axes = plt.subplots(2,3)
fig, ax : tuple
#+end_src
*** subplot with different axis
#+BEGIN_SRC python
plt.subplot(2, 1, 1)
plt.boxplot(x1)
plt.plot(1, x1.ix[-1], 'r*', markersize=15.0)

plt.subplot(2, 1, 2)
x1.plot()
# or
fig, axes = plt.subplots(2, 1, figsize=(10, 14))
axes[0].boxplot(pe000001)
axes[0].plot(1, pe000001.ix[-1], 'r*', markersize=15.0)

pe000001.plot()
#+END_SRC

*** plot a secondary y scale
#+begin_src python
df.price.plot(legend=True)
(100-df.pct_long).plot(secondary_y=True, style='g', legend=True)
#+end_src
- highlight a certain value in the plot:
#+begin_src python
a['DGAZ.US'].hist(bins=50)
plt.axvline(a['DGAZ.US'][-1], color='b', linestyle='dashed', linewidth=2)
#+end_src

*** plot a 3d figure:
#+begin_src python :tangle yes
from mpl_toolkits.mplot3d import Axes3D
import matplotlib.pyplot as plt

strike = np.linspace(50, 150, 5)
ttm = np.linspace(0.5, 2.5, 8)

strike, ttm = np.meshgrid(strike, ttm)
iv = (strike - 100) ** 2 / (100 * strike) / ttm
fig = plt.figure(figsize=(9,6))
ax = fig.gca(projection='3d')
surf = ax.plot_surface(strike, ttm, iv, rstride=2, cstride=2,
                       cmap=plt.cm.coolwarm, linewidth=0.5,
                       antialiased=True)
fig.colorbar(surf, shrink=0.5, aspect=5)
#+end_src
fig is the :class:matplotlib.figure.Figure object.

- ax can be either a single axis object or an array of axis
- objects if more than one subplot was created.

[http://docs.pythontab.com/interpy/args_kwargs/Usage_args/]

[http://python.usyiyi.cn/python_278/library/index.html]

[https://docs.python.org/2/reference/simple_stmts.html?highlight=assert]

** scipy
-  combination k from n.
$$
{\displaystyle {\binom {n}{k}}={\frac {n(n-1)\dotsb (n-k+1)}{k(k-1)\dotsb 1}},} {\binom {n}{k}}={\frac {n(n-1)\dotsb (n-k+1)}{k(k-1)\dotsb 1}}$$

which can be written using factorials as$$ {\displaystyle \textstyle {\frac {n!}{k!(n-k)!}}} \textstyle {\frac {n!}{k!(n-k)!}} $$
#+BEGIN_SRC python
>>> from scipy.special import comb
>>> k = np.array([3, 4])
>>> n = np.array([10, 10])
>>> comb(n, k, exact=False)
array([ 120.,  210.])
>>> comb(10, 3, exact=True)
120L
>>> comb(10, 3, exact=True, repetition=True)
220L
#+END_SRC
[https://docs.scipy.org/doc/scipy/reference/generated/scipy.misc.comb.html]
* Deep Learning
** Tensorflow
- install tensorflow:
#+BEGIN_SRC bash
pip install tensorflow-gpu
#+END_SRC
- test drive:
#+BEGIN_SRC bash
python -m tensorflow.models.image.mnist.convolutional
#+END_SRC
